#!/usr/bin/env python3
#
# This code is was produced by an alpha version of Brainome Daimensions(tm) and is
# licensed under GNU GPL v2.0 or higher. For details, please see:
# https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html
#
#
# Output of Brainome Daimensions(tm) 0.96 Table Compiler v0.96.
# Invocation: btc https://www.openml.org/data/get_csv/53927/eye_movements.arff -o Predictors/eye-movements_QC.py -target label -stopat 75.03 -f QC -e 100 --yes --runlocalonly
# Total compiler execution time: 0:01:22.38. Finished on: May-21-2020 20:25:53.
# This source code requires Python 3.
#
"""
Classifier Type: Quick Clustering
System Type:                        3-way classifier
Best-guess accuracy:                38.97%
Model accuracy:                     68.30% (7470/10936 correct)
Improvement over best guess:        29.33% (of possible 61.03%)
Model capacity (MEC):               3509 bits
Generalization ratio:               2.12 bits/bit
Confusion Matrix:
 [23.66% 6.78% 4.34%]
 [6.69% 27.71% 4.57%]
 [4.16% 5.15% 16.93%]

"""

# Imports -- Python3 standard library
import sys
import math
import os
import argparse
import tempfile
import csv
import binascii
import faulthandler

# Imports -- external
try:
    import numpy as np # For numpy see: http://numpy.org
    from numpy import array
except:
    print("This predictor requires the Numpy library. For installation instructions please refer to: http://numpy.org")

# Magic constants follow
# I/O buffer for clean. Reduce this constant for low memory devices. 
IOBUF = 100000000

# Ugly workaround for large classifiers
sys.setrecursionlimit(1000000)

# Training file given to compiler
TRAINFILE = "eye_movements.csv"


#Number of attributes
num_attr = 27
n_classes = 3


# Preprocessor for CSV files
def preprocess(inputcsvfile, outputcsvfile, headerless=False, testfile=False, target='', ignorecolumns=[], ignorelabels=[]):
    il=[]
    
    ignorelabels=[]
    ignorecolumns=[]
    target="label"


    if (testfile):
        target = ''
    
    with open(outputcsvfile, "w+") as outputfile:
        with open(inputcsvfile) as csvfile:
            reader = csv.reader(csvfile)
            if (headerless == False):
                header=next(reader, None)
                try:
                    if (target != ''): 
                        hc = header.index(target)
                    else:
                        hc = len(header) - 1
                        target=header[hc]
                except:
                    raise NameError("Target '" + target + "' not found! Header must be same as in file passed to btc.")
                for i in range(0, len(ignorecolumns)):
                    try:
                        col = header.index(ignorecolumns[i])
                        if (col == hc):
                            raise ValueError("Attribute '" + ignorecolumns[i] + "' is the target. Header must be same as in file passed to btc.")
                        il=il+[col]
                    except ValueError:
                        raise
                    except:
                        raise NameError("Attribute '" + ignorecolumns[i] + "' not found in header. Header must be same as in file passed to btc.")
                for i in range(0, len(header)):      
                    if (i == hc):
                        continue
                    if (i in il):
                        continue
                    print(header[i] + ",", end='', file=outputfile)
                print(header[hc], file=outputfile)

                for row in csv.DictReader(open(inputcsvfile)):
                    if (row[target] in ignorelabels):
                        continue
                    for name in header:
                        if (name in ignorecolumns):
                            continue
                        if (name==target):
                            continue
                        if (',' in row[name]):
                            print ('"' + row[name] + '"' + ",", end='', file=outputfile)
                        else:
                            print (row[name] + ",", end='', file=outputfile)
                    print (row[target], file=outputfile)

            else:
                try:
                    if (target != ""): 
                        hc = int(target)
                    else:
                        hc =- 1
                except:
                    raise NameError("No header found but attribute name given as target. Header must be same as in file passed to btc.")
                for i in range(0, len(ignorecolumns)):
                    try:
                        col = int(ignorecolumns[i])
                        if (col == hc):
                            raise ValueError("Attribute " + str(col) + " is the target. Cannot ignore. Header must be same as in file passed to btc.")
                        il = il + [col]
                    except ValueError:
                        raise
                    except:
                        raise ValueError("No header found but attribute name given in ignore column list. Header must be same as in file passed to btc.")
                for row in reader:
                    if (hc == -1):
                        hc = len(row) - 1
                    if (row[hc] in ignorelabels):
                        continue
                    for i in range(0, len(row)):
                        if (i in il):
                            continue
                        if (i == hc):
                            continue
                        if (',' in row[i]):
                            print ('"' + row[i] + '"'+",", end='', file=outputfile)
                        else:
                            print(row[i]+",", end = '', file=outputfile)
                    print (row[hc], file=outputfile)

def clean(filename, outfile, rounding=-1, headerless=False, testfile=False):
    
    clean.classlist = []
    clean.testfile = testfile
    clean.mapping = {}
    

    def convert(cell):
        value = str(cell)
        try:
            result = int(value)
            return result
        except:
            try:
                result = float(value)
                if (rounding != -1):
                    result = int(result * math.pow(10, rounding)) / math.pow(10, rounding)
                return result
            except:
                result = (binascii.crc32(value.encode('utf8')) % (1 << 32))
                return result

    # function to return key for any value 
    def get_key(val, clean_classmapping):
        if clean_classmapping == {}:
            return val
        for key, value in clean_classmapping.items(): 
            if val == value:
                return key
        if val not in list(clean_classmapping.values):
            raise ValueError("Label key does not exist")

    def convertclassid(cell):
        if (clean.testfile):
            return convert(cell)
        value = str(cell)
        if (value == ''):
            raise ValueError("All cells in the target column must contain a class label.")

        if (not clean.mapping == {}):
            result = -1
            try:
                result = clean.mapping[cell]
            except:
                raise ValueError("Class label '" + value + "' encountered in input not defined in user-provided mapping.")
            if (not result == int(result)):
                raise ValueError("Class labels must be mapped to integer.")
            if (not str(result) in clean.classlist):
                clean.classlist = clean.classlist + [str(result)]
            return result
        try:
            result = float(cell)
            if (rounding != -1):
                result = int(result * math.pow(10, rounding)) / math.pow(10, rounding)
            else:
                result = int(int(result * 100) / 100)  # round classes to two digits

            if (not str(result) in clean.classlist):
                clean.classlist = clean.classlist + [str(result)]
        except:
            result = (binascii.crc32(value.encode('utf8')) % (1 << 32))
            if (result in clean.classlist):
                result = clean.classlist.index(result)
            else:
                clean.classlist = clean.classlist + [result]
                result = clean.classlist.index(result)
            if (not result == int(result)):
                raise ValueError("Class labels must be mappable to integer.")
        finally:
            if (result < 0):
                raise ValueError("Integer class labels must be positive and contiguous.")

        return result

    rowcount = 0
    with open(filename) as csv_file:
        reader = csv.reader(csv_file)
        f = open(outfile, "w+")
        if (headerless == False):
            next(reader, None)
        outbuf = []
        for row in reader:
            if (row == []):  # Skip empty rows
                continue
            rowcount = rowcount + 1
            rowlen = num_attr
            if (not testfile):
                rowlen = rowlen + 1    
            if (not len(row) == rowlen):
                raise ValueError("Column count must match trained predictor. Row " + str(rowcount) + " differs.")
            i = 0
            for elem in row:
                if(i + 1 < len(row)):
                    outbuf.append(str(convert(elem)))
                    outbuf.append(',')
                else:
                    classid = str(convertclassid(elem))
                    outbuf.append(classid)
                i = i + 1
            if (len(outbuf) < IOBUF):
                outbuf.append(os.linesep)
            else:
                print(''.join(outbuf), file=f)
                outbuf = []
        print(''.join(outbuf), end="", file=f)
        f.close()

        if (testfile == False and not len(clean.classlist) >= 2):
            raise ValueError("Number of classes must be at least 2.")

        return get_key, clean.mapping

# Calculate energy

# Imports -- external
import numpy as np # For numpy see: http://numpy.org
from numpy import array
energy_thresholds = array([1297.52865, 1403.13005, 1414.9046500000002, 1467.2724, 1492.2032, 1517.5232500000002, 1526.85465, 1559.3188999999998, 1578.70485, 1606.0651500000001, 1631.56265, 1651.0967, 1675.56465, 1685.1186500000001, 1726.7399500000001, 1736.2067499999998, 1764.84205, 1784.12865, 1805.8935999999999, 1808.42445, 1814.4445, 1836.1131, 1852.0924499999999, 1876.6700500000002, 1885.86695, 1909.4612, 1918.4531000000002, 1959.8595500000001, 1968.8641000000002, 1970.7937000000002, 1975.1453000000001, 1990.7176, 2000.9375, 2001.76105, 2030.46765, 2039.9502499999999, 2047.995, 2056.2961999999998, 2069.0902, 2074.2993500000002, 2079.6772499999997, 2095.3327, 2103.6291499999998, 2110.8302, 2129.6039499999997, 2140.2355, 2144.6828000000005, 2152.30735, 2159.6632, 2163.89125, 2165.2892, 2167.1953999999996, 2179.9709, 2196.5169, 2198.3475500000004, 2223.9525000000003, 2226.7985, 2237.64475, 2244.4646000000002, 2248.3589, 2250.0283499999996, 2251.86805, 2257.2289, 2259.2716499999997, 2260.7460499999997, 2261.59815, 2275.2391500000003, 2277.01625, 2281.7339, 2288.2126000000003, 2292.43705, 2293.74255, 2298.7819499999996, 2317.74975, 2320.7817999999997, 2326.8146500000003, 2329.943, 2333.7154, 2337.96255, 2339.56095, 2345.50105, 2358.14345, 2364.7617, 2384.2455499999996, 2387.5477, 2388.89375, 2394.2925999999998, 2396.9951499999997, 2398.7702499999996, 2400.9861, 2410.87755, 2414.1721, 2417.9553499999997, 2421.0782, 2427.4556000000002, 2433.23145, 2435.9946, 2437.58255, 2443.69505, 2445.7188499999997, 2454.1404, 2455.6965, 2457.8318500000005, 2463.0501, 2463.7371999999996, 2464.4491, 2468.40175, 2472.314, 2475.2299, 2478.8239, 2480.5007, 2482.77905, 2485.58065, 2488.43615, 2491.9870499999997, 2496.7529, 2500.91385, 2510.395, 2513.8675, 2517.6229, 2535.92105, 2549.2483, 2557.52545, 2564.9750999999997, 2567.0056999999997, 2569.2326, 2570.9302, 2574.58915, 2576.42645, 2581.3323, 2588.1748, 2591.3600500000002, 2594.4130000000005, 2596.3456, 2607.03055, 2617.1961, 2621.0465, 2631.0177000000003, 2636.8658, 2639.4143, 2645.3926, 2649.8453, 2664.3746499999997, 2670.3247, 2674.526, 2681.5922, 2684.3508, 2686.25555, 2687.65765, 2691.5461, 2699.4432500000003, 2700.5176, 2707.59755, 2707.71565, 2720.3487999999998, 2722.5033999999996, 2724.87785, 2726.4555, 2728.8842000000004, 2730.9382, 2734.8894, 2738.53295, 2738.90695, 2740.52035, 2740.8011, 2744.3723999999997, 2745.9347, 2746.88115, 2750.5833000000002, 2756.20855, 2756.2846, 2763.2807000000003, 2765.35285, 2772.7598, 2780.47235, 2782.8801999999996, 2792.8046, 2798.9216, 2801.5896000000002, 2805.52175, 2807.4716, 2810.5068499999998, 2813.0168, 2814.5186999999996, 2816.4658, 2822.1896, 2823.924, 2828.5966, 2828.82795, 2829.43915, 2830.8443500000003, 2833.1835, 2838.1947, 2842.1332, 2844.86565, 2860.7192, 2861.9703499999996, 2863.50385, 2869.3968, 2883.2596999999996, 2884.9866, 2888.9795999999997, 2892.50675, 2892.89495, 2895.0378, 2896.5982000000004, 2899.8036, 2905.3870500000003, 2908.8692, 2909.9057000000003, 2911.145, 2915.6597, 2917.7367000000004, 2918.14255, 2924.7635499999997, 2930.1542, 2942.9636499999997, 2945.0663999999997, 2946.38115, 2948.5940499999997, 2949.5723499999995, 2950.4550499999996, 2953.18545, 2958.05425, 2962.1234999999997, 2966.9629999999997, 2971.3278999999998, 2974.5269, 2975.2182000000003, 2990.3932, 2992.6458000000002, 2994.99215, 2996.0712, 2997.1118, 2997.6036, 3003.6082, 3007.2338500000005, 3011.90655, 3016.2101000000002, 3019.1982, 3021.55235, 3024.3723499999996, 3026.76725, 3027.9686, 3033.2607500000004, 3045.3559, 3049.7647, 3055.37525, 3059.0719499999996, 3059.3549000000003, 3064.1684999999998, 3066.93775, 3072.8414000000002, 3072.9931500000002, 3073.6600000000003, 3074.3307000000004, 3084.7816000000003, 3089.2131, 3091.9606999999996, 3096.2747999999997, 3100.24165, 3102.749, 3105.5657, 3111.1398, 3114.6417, 3117.0964, 3119.8540000000003, 3121.5663000000004, 3130.5458, 3134.53035, 3136.19255, 3137.72285, 3138.50115, 3142.1947499999997, 3145.0566, 3146.48875, 3149.0339000000004, 3150.30725, 3150.91625, 3151.9929, 3155.3559999999998, 3158.2472, 3161.6305999999995, 3166.32275, 3170.87205, 3173.0685000000003, 3174.4753, 3175.5335, 3177.81465, 3182.96325, 3189.2001499999997, 3190.6663, 3192.1906, 3193.7913, 3194.0913, 3195.61035, 3197.9554, 3200.71155, 3202.6041999999998, 3203.71415, 3206.3797999999997, 3225.3219500000005, 3239.72965, 3242.31005, 3248.4285999999997, 3249.83995, 3256.71875, 3259.858, 3264.755, 3267.15885, 3267.822, 3270.2192999999997, 3271.56735, 3272.5365, 3274.40765, 3275.08185, 3277.9967500000002, 3281.3407, 3284.0552000000002, 3285.72465, 3293.04965, 3298.2313000000004, 3308.4269, 3312.0503, 3314.96825, 3317.3083500000002, 3320.4152, 3336.5175, 3337.78715, 3340.2321, 3343.1106, 3345.01955, 3349.3216, 3351.322, 3352.7591, 3352.8295000000003, 3353.03885, 3356.98535, 3357.6806, 3358.6181500000002, 3361.5616, 3369.41485, 3384.7783, 3386.6622, 3389.61405, 3389.9722, 3390.66245, 3391.4084000000003, 3397.9255000000003, 3408.42075, 3409.89195, 3410.84185, 3412.45645, 3415.6971000000003, 3418.2952, 3423.9031999999997, 3424.7322999999997, 3428.00835, 3431.6198000000004, 3437.31235, 3443.1496500000003, 3443.97365, 3445.5299, 3446.59095, 3447.0235000000002, 3447.6243000000004, 3448.88895, 3452.3358, 3455.02875, 3455.71885, 3463.1196, 3469.21345, 3469.7699000000002, 3471.2033, 3477.85505, 3480.2514, 3488.5829000000003, 3493.9519, 3500.13195, 3501.95345, 3504.13085, 3510.1234, 3511.6857, 3514.7673999999997, 3518.86495, 3520.2691999999997, 3522.31175, 3527.68885, 3529.9282, 3533.7605, 3545.1174, 3547.036, 3548.70795, 3551.0592500000002, 3552.83675, 3553.09285, 3554.1169, 3557.16335, 3561.4004999999997, 3565.3412499999995, 3568.9172, 3571.5433000000003, 3574.04885, 3574.83035, 3575.1724, 3580.5352999999996, 3587.1004999999996, 3591.04045, 3596.14335, 3599.1382, 3600.01365, 3614.67415, 3623.2101, 3625.2366, 3627.91395, 3632.7535, 3634.9482500000004, 3639.66485, 3645.5242, 3648.2241999999997, 3649.3451999999997, 3653.4972500000003, 3656.10615, 3661.97185, 3666.9746999999998, 3671.06635, 3679.17375, 3685.3399499999996, 3702.8867, 3710.8342000000002, 3714.3238499999998, 3733.3009, 3736.1570500000003, 3737.1806500000002, 3744.7014499999996, 3752.25925, 3755.02725, 3760.73835, 3767.1843500000004, 3773.64825, 3777.4483499999997, 3779.4004999999997, 3785.6821499999996, 3796.44655, 3797.65105, 3803.9863, 3811.8667, 3821.3736, 3826.05285, 3831.62645, 3834.62745, 3836.8332499999997, 3837.6382, 3838.5653, 3839.9438499999997, 3843.4289, 3848.9951, 3851.22115, 3853.17875, 3853.89955, 3857.89905, 3860.1272, 3865.3966499999997, 3869.65415, 3870.39735, 3871.132, 3876.82395, 3880.1748, 3891.7599499999997, 3893.4968, 3904.8654500000002, 3909.36795, 3910.40705, 3915.21785, 3916.9472, 3920.59495, 3925.659, 3928.90355, 3930.7758999999996, 3950.01905, 3955.02355, 3975.4451499999996, 3990.6906, 3998.2342500000004, 4002.3728, 4003.2468, 4006.4431999999997, 4014.1294, 4015.29065, 4019.2030000000004, 4022.3926500000002, 4023.7692500000003, 4032.7860499999997, 4035.70625, 4035.7433, 4040.1513999999997, 4045.0715499999997, 4051.16805, 4052.9937, 4056.3725, 4062.7351, 4072.04475, 4080.7132, 4086.10055, 4089.33315, 4099.76585, 4107.42645, 4111.81125, 4115.048999999999, 4128.9309, 4131.269, 4133.5594, 4136.02735, 4136.66495, 4139.6098999999995, 4142.502, 4144.34875, 4151.213949999999, 4158.472, 4160.36275, 4163.0916, 4172.2121, 4179.88055, 4180.5481, 4190.696099999999, 4194.24375, 4196.47925, 4197.57125, 4204.7065, 4210.81095, 4218.1801, 4220.56815, 4221.44555, 4222.5830000000005, 4235.1932, 4251.8818, 4264.18045, 4265.9679, 4275.321, 4280.5089, 4282.98505, 4287.3979500000005, 4289.76715, 4294.302099999999, 4302.9241, 4306.142250000001, 4309.3689, 4312.8827, 4315.706050000001, 4321.438749999999, 4324.21145, 4327.397, 4334.3328, 4339.9193, 4342.669, 4348.7759, 4350.1378, 4350.65435, 4354.9673, 4359.4926, 4361.05735, 4362.543900000001, 4368.64855, 4370.77075, 4373.93275, 4381.45635, 4387.00395, 4387.6978, 4390.07785, 4392.5121, 4395.004, 4397.3556499999995, 4400.77795, 4402.491550000001, 4411.9761, 4415.48775, 4417.49245, 4420.084, 4422.2805, 4424.719950000001, 4426.02715, 4429.2955999999995, 4431.0082999999995, 4434.99705, 4435.84715, 4436.5359, 4438.79785, 4442.46115, 4444.0845, 4444.23125, 4446.4056, 4446.900450000001, 4447.12805, 4452.0287, 4457.52305, 4460.0845, 4473.68175, 4480.723550000001, 4485.93375, 4487.4319000000005, 4491.88985, 4493.53405, 4496.4785, 4502.15235, 4506.4981, 4510.23175, 4513.565549999999, 4513.9947999999995, 4514.939399999999, 4516.1252, 4516.7723000000005, 4521.418250000001, 4525.31655, 4527.8595000000005, 4529.71835, 4532.8386, 4534.73115, 4557.90285, 4561.8208, 4562.7718, 4564.9637999999995, 4567.078149999999, 4567.54185, 4573.453100000001, 4574.3293, 4578.55865, 4585.5815999999995, 4589.9782, 4591.64865, 4596.32245, 4599.56225, 4602.564899999999, 4604.602199999999, 4607.4851, 4610.05265, 4615.6799, 4617.078799999999, 4619.013349999999, 4622.9721, 4623.5310500000005, 4624.6003, 4626.7988000000005, 4632.50635, 4637.02705, 4640.8589, 4642.818800000001, 4646.92765, 4651.68335, 4657.91145, 4663.03795, 4665.953149999999, 4677.58855, 4679.95765, 4681.6583, 4686.795249999999, 4697.682199999999, 4699.38495, 4711.29835, 4714.5226999999995, 4719.95235, 4726.060450000001, 4730.409, 4733.3796999999995, 4733.60255, 4746.648499999999, 4748.0768499999995, 4749.579900000001, 4750.94745, 4758.3449, 4767.39165, 4770.810600000001, 4773.0128, 4774.24005, 4778.7621, 4781.24625, 4782.872600000001, 4784.714, 4785.35885, 4786.7099, 4788.39445, 4791.2402999999995, 4796.0818500000005, 4807.4325, 4813.0333, 4820.4716, 4821.927, 4824.77745, 4827.9995, 4834.8053500000005, 4837.549150000001, 4839.59355, 4844.529549999999, 4848.3884, 4852.66565, 4858.0833, 4866.75435, 4868.84995, 4873.36885, 4879.0683, 4881.4220000000005, 4882.40475, 4882.7275, 4883.09965, 4887.5534, 4890.9644499999995, 4893.29055, 4896.76665, 4904.77795, 4910.82135, 4911.002850000001, 4922.094150000001, 4926.64475, 4929.08245, 4929.38895, 4930.3078, 4931.552900000001, 4933.876, 4955.966549999999, 4958.485199999999, 4970.2708, 4971.44295, 4973.6872, 4980.883750000001, 4995.7549, 5000.3213, 5009.08985, 5011.3992, 5012.68625, 5013.3556, 5017.5655, 5022.031849999999, 5024.7462, 5032.25985, 5033.57965, 5034.78185, 5036.64135, 5059.6888, 5061.1659500000005, 5062.7068, 5064.40175, 5069.46895, 5075.4306, 5079.676799999999, 5080.74205, 5081.5381, 5090.3739000000005, 5099.3521, 5103.84635, 5106.788850000001, 5110.3062, 5115.51465, 5119.77575, 5120.7031, 5121.60725, 5122.40135, 5123.70155, 5126.78835, 5129.55795, 5135.6273, 5138.96275, 5142.717299999999, 5146.40975, 5154.67225, 5159.77975, 5164.784250000001, 5172.253549999999, 5179.80865, 5189.466350000001, 5193.35355, 5194.495800000001, 5196.79535, 5201.5602, 5206.7043, 5209.2533, 5211.9252, 5214.0409500000005, 5222.0650000000005, 5224.60595, 5226.78085, 5227.9283, 5242.92975, 5243.6283, 5246.579299999999, 5250.95095, 5252.61085, 5258.7669, 5259.50555, 5259.74635, 5267.3585, 5275.126700000001, 5277.872600000001, 5279.639450000001, 5281.31835, 5283.725850000001, 5284.513349999999, 5284.9166000000005, 5290.023300000001, 5293.9414, 5297.7383, 5309.614100000001, 5318.2132, 5320.9192, 5325.2819500000005, 5333.2522, 5335.06085, 5336.57095, 5337.631350000001, 5338.2582999999995, 5340.19485, 5344.65635, 5345.900799999999, 5347.7558, 5349.829299999999, 5352.31725, 5354.69305, 5356.011, 5359.87945, 5360.8586, 5365.54515, 5370.405000000001, 5375.93895, 5379.1875, 5380.3553, 5383.870800000001, 5390.126, 5393.04435, 5394.9257, 5398.9844, 5402.3577000000005, 5402.672850000001, 5403.75645, 5405.75525, 5407.30205, 5407.99375, 5408.5823, 5409.5443000000005, 5414.14445, 5415.5551000000005, 5427.37535, 5429.81315, 5437.67095, 5438.6422999999995, 5439.98235, 5442.6215, 5450.3414999999995, 5453.2665, 5464.480149999999, 5465.43325, 5465.6141, 5465.833549999999, 5466.30825, 5470.9612, 5486.9134, 5488.657150000001, 5490.6103, 5492.33, 5497.6219, 5503.300300000001, 5505.30385, 5506.79665, 5509.175649999999, 5513.33965, 5525.31945, 5534.3158, 5535.7685, 5536.17815, 5542.2493, 5546.9141, 5549.5754, 5554.4367999999995, 5554.7972, 5557.42375, 5564.16525, 5569.08355, 5577.83455, 5579.939899999999, 5581.516299999999, 5582.97825, 5586.45085, 5594.188099999999, 5597.1391, 5603.7223, 5607.17885, 5609.277550000001, 5611.050450000001, 5611.7462, 5612.03135, 5612.9151, 5613.599550000001, 5614.185, 5615.0031500000005, 5615.4895, 5615.9291, 5621.0238, 5627.48715, 5632.3927, 5635.24805, 5636.55445, 5636.91965, 5637.99275, 5641.46815, 5642.8547, 5653.9869499999995, 5655.1768999999995, 5655.8778, 5657.8228500000005, 5661.18555, 5665.874250000001, 5668.8534500000005, 5672.15835, 5678.12725, 5680.23835, 5680.84485, 5684.23985, 5687.6062, 5690.659750000001, 5691.54765, 5692.446550000001, 5694.3634, 5695.63125, 5706.96275, 5707.8628, 5710.21445, 5710.764050000001, 5713.398, 5717.3574499999995, 5722.4927, 5729.764149999999, 5749.4822, 5752.72875, 5755.165, 5758.4393, 5761.3284, 5764.0603, 5765.729, 5768.3273, 5770.54255, 5772.1098, 5788.2315, 5788.665150000001, 5789.0229, 5789.47285, 5791.8266, 5794.29165, 5802.28695, 5805.47675, 5808.4334499999995, 5810.2806, 5811.45625, 5816.542450000001, 5822.723550000001, 5836.493399999999, 5843.0413, 5847.16375, 5851.91735, 5853.427299999999, 5855.06335, 5856.6681, 5859.0575499999995, 5861.14225, 5862.6105, 5863.4283, 5865.4175, 5869.771049999999, 5877.2407, 5881.173049999999, 5882.76965, 5885.2162499999995, 5897.14995, 5903.248, 5907.9806, 5912.9982, 5920.862950000001, 5924.77125, 5927.90525, 5930.2981, 5930.76275, 5931.25805, 5935.59525, 5938.268050000001, 5938.4217499999995, 5939.0555, 5943.43425, 5946.77545, 5950.00365, 5957.5699, 5964.467500000001, 5965.30345, 5966.592500000001, 5967.5521499999995, 5970.6012, 5979.65415, 5982.4904, 5984.359, 5989.733549999999, 5999.23755, 6000.5059, 6000.567000000001, 6000.87485, 6001.5731, 6004.5854, 6006.194149999999, 6020.4522, 6026.56155, 6035.0930499999995, 6037.130950000001, 6038.3505000000005, 6039.205599999999, 6040.0298, 6042.593849999999, 6045.36975, 6047.13065, 6048.3261999999995, 6048.7176, 6051.8675, 6053.5652, 6066.2366, 6069.362749999999, 6070.465749999999, 6080.629999999999, 6093.2855, 6096.65345, 6099.7019, 6102.812550000001, 6105.47735, 6107.26565, 6108.13, 6109.8775000000005, 6111.0579, 6121.54475, 6122.298500000001, 6123.167800000001, 6123.541000000001, 6123.90265, 6135.306549999999, 6139.3777, 6144.90665, 6153.89185, 6156.309950000001, 6171.69695, 6176.0896, 6176.375099999999, 6177.1149000000005, 6183.2852, 6185.5909, 6187.90425, 6197.20335, 6201.199250000001, 6204.83945, 6206.9075, 6214.52065, 6222.2646, 6224.1411499999995, 6225.00175, 6228.304550000001, 6231.80985, 6233.57835, 6235.8538, 6240.0239, 6243.7973999999995, 6244.7747, 6249.650750000001, 6251.20535, 6257.7418, 6259.5893, 6260.9524, 6261.860199999999, 6267.69205, 6274.5202, 6277.50215, 6281.34475, 6283.6032, 6284.506449999999, 6287.5560000000005, 6290.0499, 6297.882, 6300.22795, 6301.7996, 6303.46195, 6312.611800000001, 6317.7809, 6319.1085, 6325.81675, 6328.85245, 6330.5072, 6331.5501, 6331.64855, 6334.76425, 6338.0106, 6340.9524, 6343.9671, 6344.4703, 6349.937449999999, 6351.1156, 6359.7963, 6362.29335, 6364.11455, 6367.535900000001, 6371.2973999999995, 6374.809649999999, 6379.9247, 6382.003199999999, 6386.008250000001, 6392.63385, 6393.17685, 6394.932049999999, 6398.3181, 6401.370199999999, 6404.7154, 6406.8664499999995, 6413.40285, 6416.91425, 6425.0744, 6426.1922, 6427.59155, 6431.7407, 6437.66445, 6440.224050000001, 6440.69755, 6444.82545, 6446.57365, 6448.27535, 6451.40595, 6456.96645, 6463.5712, 6468.349700000001, 6469.33295, 6469.9888, 6472.22545, 6474.3598999999995, 6475.2291000000005, 6475.813400000001, 6476.167800000001, 6476.274950000001, 6478.094300000001, 6486.5964, 6489.72965, 6493.4919, 6503.1294, 6510.47385, 6515.65185, 6519.77005, 6526.814, 6530.23755, 6532.55615, 6534.81365, 6537.6795, 6541.30565, 6541.5659, 6542.06845, 6542.4307, 6542.51945, 6543.1788, 6544.23165, 6546.8027, 6551.05215, 6553.2330999999995, 6553.3847000000005, 6553.6921, 6554.087, 6556.2888, 6563.2279499999995, 6567.02, 6567.7173999999995, 6573.4771, 6577.840200000001, 6580.22165, 6588.50075, 6609.994, 6611.2967, 6614.1547, 6617.3126, 6618.0477, 6618.6321, 6625.975850000001, 6630.701650000001, 6633.653899999999, 6638.6245, 6643.8409, 6647.912700000001, 6649.215249999999, 6650.8824, 6653.476549999999, 6654.955599999999, 6655.97535, 6656.96735, 6660.9267500000005, 6668.4114, 6673.584100000001, 6674.84265, 6676.668, 6678.5864, 6683.308300000001, 6684.9992, 6688.86145, 6695.6374, 6698.71, 6708.956899999999, 6709.9628, 6710.680700000001, 6711.3757000000005, 6713.18535, 6713.5949, 6716.69935, 6718.7744, 6720.876, 6724.032, 6726.484399999999, 6730.03675, 6735.2591, 6736.4404, 6738.2158500000005, 6738.89835, 6739.71315, 6743.3336, 6746.82, 6748.28295, 6749.8207, 6757.04115, 6766.32645, 6767.9426, 6768.63445, 6772.0927, 6774.2647, 6780.6431999999995, 6791.38185, 6815.41385, 6818.105, 6818.5543, 6819.0283500000005, 6828.09375, 6828.44645, 6829.40575, 6830.52425, 6837.71845, 6841.81815, 6844.6774000000005, 6845.168, 6850.40725, 6851.63785, 6852.8684, 6858.2513, 6863.3529, 6870.77145, 6872.6870499999995, 6877.5899, 6880.9148000000005, 6891.73225, 6892.81265, 6893.64565, 6893.89495, 6900.864, 6908.1356, 6908.73875, 6914.974099999999, 6918.47185, 6919.1247, 6920.7919, 6921.30135, 6927.2365, 6930.84585, 6933.7181, 6935.4771, 6937.329949999999, 6940.2004, 6941.74085, 6943.6409, 6947.61405, 6950.34055, 6950.5895, 6951.1824, 6951.88065, 6954.81865, 6957.89235, 6960.16445, 6963.38505, 6969.7994, 6974.21795, 6977.1051, 6978.715249999999, 6981.0247, 6983.3682, 6986.49975, 6989.2554, 6993.676450000001, 6996.8272, 7000.4052, 7000.651900000001, 7002.323850000001, 7004.815149999999, 7006.40725, 7007.3453, 7008.68215, 7011.1983, 7015.90835, 7024.9201, 7030.3872, 7032.3318500000005, 7034.4737000000005, 7042.38005, 7045.33665, 7048.22495, 7048.92215, 7049.207549999999, 7050.48725, 7052.0509, 7054.557849999999, 7055.7253, 7056.60535, 7060.8083, 7063.3807, 7065.15535, 7070.835650000001, 7072.5265500000005, 7081.30755, 7082.40505, 7087.68305, 7093.74575, 7102.01, 7103.89155, 7108.190850000001, 7112.42085, 7113.03945, 7115.8773, 7116.9324, 7118.1777, 7120.3478000000005, 7122.87255, 7123.457549999999, 7126.4959, 7129.7546999999995, 7130.51195, 7130.7919, 7131.8895, 7151.4024, 7153.7973, 7155.4658500000005, 7157.2474, 7168.0494, 7169.3835, 7170.21665, 7173.5749000000005, 7180.719499999999, 7182.74825, 7191.701349999999, 7194.13465, 7194.50415, 7196.5056, 7201.7204, 7202.527599999999, 7205.222, 7211.66185, 7218.6819, 7219.81235, 7220.34395, 7221.50395, 7231.2266, 7232.5768499999995, 7237.30335, 7239.4108, 7247.4642, 7250.73315, 7252.3676, 7253.93965, 7255.2652, 7255.37115, 7257.88645, 7260.05055, 7261.64775, 7262.2900500000005, 7263.805050000001, 7266.2567, 7268.580550000001, 7271.2735, 7274.06235, 7274.2301, 7276.11455, 7277.49055, 7278.9486, 7279.819100000001, 7281.8659, 7285.7176500000005, 7286.412550000001, 7288.121, 7290.20705, 7293.4358, 7297.1606, 7300.7132, 7302.54725, 7304.1335500000005, 7310.787, 7318.0463, 7321.2467, 7327.0807, 7328.498450000001, 7330.1489, 7331.41115, 7338.4247, 7339.155900000001, 7339.90765, 7343.5159, 7350.8175, 7351.86815, 7352.9089, 7355.148499999999, 7357.04225, 7366.2148, 7367.0776000000005, 7369.849249999999, 7375.92865, 7380.02625, 7383.6312, 7394.3312000000005, 7396.0177, 7396.44185, 7397.3414, 7399.68915, 7401.3874, 7401.91245, 7403.298199999999, 7404.5159, 7405.26315, 7411.34175, 7417.19155, 7418.4367999999995, 7420.3423999999995, 7421.85245, 7427.882750000001, 7430.06985, 7433.3938, 7434.652050000001, 7434.9781, 7435.2453000000005, 7439.243200000001, 7447.0229, 7448.4798, 7450.35425, 7452.02015, 7452.59535, 7454.30845, 7455.04725, 7455.7266, 7455.9308, 7468.87895, 7470.0118999999995, 7475.5136999999995, 7477.06515, 7477.2939, 7477.9679, 7479.0175, 7481.89525, 7495.0633, 7497.613649999999, 7506.30675, 7516.09075, 7518.98025, 7522.485849999999, 7526.244049999999, 7530.0275, 7530.620849999999, 7531.4272, 7532.26195, 7532.9318, 7538.75805, 7542.570599999999, 7544.037899999999, 7545.689049999999, 7547.81885, 7552.015600000001, 7555.4881000000005, 7559.402050000001, 7562.9048, 7565.5405, 7570.0461000000005, 7581.15185, 7586.4856, 7591.81525, 7604.83225, 7606.4548, 7610.401099999999, 7611.571, 7613.781599999999, 7617.63775, 7621.3502, 7632.592549999999, 7633.250599999999, 7637.84, 7644.40175, 7646.62335, 7647.2412, 7652.75705, 7653.22685, 7653.620199999999, 7656.719349999999, 7661.259, 7663.102199999999, 7664.1458, 7665.0923, 7675.04245, 7679.40735, 7682.6962, 7684.5419, 7688.4082, 7689.9481, 7692.40675, 7695.49845, 7701.17395, 7709.791300000001, 7713.1109, 7718.2639500000005, 7719.2929, 7735.19715, 7736.37875, 7737.308000000001, 7738.997800000001, 7744.48395, 7746.3188, 7748.04985, 7750.0017, 7752.658149999999, 7753.88775, 7754.99965, 7759.9604, 7760.7554, 7762.684450000001, 7765.79805, 7776.5804, 7790.46755, 7795.36625, 7797.16435, 7799.0881, 7801.0849, 7803.465, 7808.5738, 7816.11915, 7817.94455, 7823.70605, 7825.629349999999, 7829.278200000001, 7831.3946, 7832.2801, 7832.93175, 7834.490449999999, 7835.6858999999995, 7835.95385, 7837.07325, 7838.0162, 7838.3126, 7840.28865, 7843.0905, 7846.2341, 7850.102150000001, 7857.50645, 7858.1825, 7869.375599999999, 7870.61805, 7871.892, 7872.605, 7873.5072, 7874.64645, 7875.7877, 7877.130950000001, 7877.8279, 7878.8686, 7881.14235, 7883.4189, 7885.36305, 7889.1173, 7891.998149999999, 7895.56355, 7897.6906, 7899.24765, 7899.9521, 7905.3258000000005, 7907.85145, 7912.5666, 7914.25745, 7916.24975, 7919.05925, 7920.59255, 7922.42685, 7922.78075, 7924.590900000001, 7927.19355, 7928.41205, 7929.599700000001, 7931.6849, 7936.1611, 7939.62455, 7945.06735, 7957.9427, 7962.0073, 7966.706099999999, 7969.43485, 7969.998949999999, 7978.02245, 7979.892150000001, 7986.7798999999995, 7988.8758, 7989.837949999999, 7992.1404999999995, 7992.98625, 7995.7448, 7996.1069, 7996.6412, 7998.705400000001, 8000.65185, 8006.502350000001, 8007.34065, 8007.66885, 8008.081899999999, 8012.0628, 8020.947700000001, 8025.2123, 8025.843150000001, 8026.2144499999995, 8027.575, 8029.447749999999, 8031.40625, 8032.756, 8033.00515, 8034.646699999999, 8036.457899999999, 8038.65755, 8045.378650000001, 8049.4571, 8049.6789499999995, 8050.1739, 8051.92915, 8054.7376, 8057.19995, 8060.065699999999, 8062.3045999999995, 8063.7702, 8065.8867, 8066.1498, 8067.9326, 8069.48085, 8070.86255, 8071.346299999999, 8077.5234, 8078.812599999999, 8079.69205, 8081.1618, 8087.1309, 8088.3114000000005, 8089.66315, 8092.2994, 8096.557150000001, 8099.23805, 8100.70315, 8103.9355, 8107.2351, 8111.019900000001, 8113.96935, 8116.39615, 8117.36345, 8118.486800000001, 8122.541649999999, 8123.42395, 8130.199200000001, 8131.1542, 8131.982599999999, 8139.1776, 8141.39185, 8142.7757, 8142.87025, 8143.336450000001, 8144.93525, 8147.6841, 8154.9491, 8156.4148, 8165.226699999999, 8165.9310000000005, 8168.393999999999, 8169.751249999999, 8173.933300000001, 8175.3655, 8177.3814999999995, 8183.54605, 8192.662, 8195.052599999999, 8197.0045, 8197.22, 8198.848899999999, 8202.70225, 8206.3131, 8209.01095, 8210.90365, 8213.73155, 8217.61405, 8220.7745, 8223.0033, 8224.18015, 8224.92265, 8227.37025, 8230.378, 8231.89235, 8237.3323, 8237.60875, 8237.9222, 8238.76135, 8239.5867, 8242.05325, 8245.211449999999, 8255.57255, 8256.0385, 8256.8057, 8270.6951, 8276.710050000002, 8286.45485, 8289.8011, 8292.575850000001, 8296.6036, 8300.1252, 8304.659749999999, 8306.7657, 8308.371299999999, 8311.164850000001, 8325.13285, 8327.410899999999, 8331.457999999999, 8338.48785, 8340.37355, 8340.861, 8341.6197, 8344.6703, 8347.1194, 8348.36935, 8351.8609, 8359.4896, 8361.412199999999, 8365.50085, 8369.0451, 8370.3431, 8371.0078, 8371.71185, 8372.928100000001, 8373.76115, 8375.1965, 8375.990099999999, 8376.277699999999, 8379.78575, 8383.119999999999, 8385.13525, 8386.37955, 8391.3456, 8398.01255, 8399.42325, 8399.856749999999, 8400.92345, 8402.5644, 8404.0017, 8405.4744, 8406.451099999998, 8408.258699999998, 8409.72245, 8410.8773, 8411.652300000002, 8413.02635, 8421.3102, 8422.5394, 8424.54775, 8428.694350000002, 8430.0193, 8434.6759, 8439.0479, 8440.06315, 8444.332550000001, 8446.170600000001, 8446.596300000001, 8449.94755, 8451.01325, 8453.454600000001, 8455.8763, 8457.1867, 8458.4146, 8461.444650000001, 8464.629700000001, 8465.664499999999, 8466.6073, 8467.2973, 8468.8599, 8471.1934, 8472.4777, 8474.75705, 8477.071049999999, 8478.04565, 8479.10745, 8481.028, 8483.492, 8485.54295, 8487.37705, 8489.1173, 8489.69095, 8492.4407, 8494.1584, 8494.995050000001, 8499.14, 8500.70225, 8502.23125, 8503.5822, 8504.8154, 8506.490000000002, 8507.59555, 8508.065200000001, 8509.264650000001, 8510.236550000001, 8511.741300000002, 8513.145550000001, 8515.1852, 8517.904050000001, 8519.736550000001, 8520.3703, 8522.75575, 8526.71275, 8529.08265, 8532.631150000001, 8534.943, 8537.35875, 8541.68645, 8545.37065, 8545.887200000001, 8546.420549999999, 8550.6937, 8551.105800000001, 8553.0789, 8554.7214, 8557.266800000001, 8562.5673, 8568.9106, 8576.17755, 8577.43355, 8584.19845, 8584.9558, 8586.279999999999, 8588.773000000001, 8590.2379, 8593.7533, 8596.955549999999, 8602.4355, 8606.39945, 8606.96215, 8608.21645, 8609.388050000001, 8609.853650000001, 8610.423050000001, 8612.7988, 8616.8104, 8617.6895, 8621.1888, 8622.01735, 8624.4087, 8632.448, 8632.579150000001, 8632.7203, 8633.98135, 8637.863949999999, 8640.1548, 8643.2203, 8645.05095, 8645.698550000001, 8646.79245, 8648.0881, 8650.0548, 8652.7169, 8653.5404, 8654.047749999998, 8654.702949999999, 8657.511050000001, 8662.72025, 8664.415700000001, 8666.511, 8668.60195, 8669.8597, 8670.6522, 8677.56225, 8679.2533, 8680.068299999999, 8685.25095, 8685.51225, 8688.221249999999, 8693.761050000001, 8695.6568, 8697.1396, 8698.0661, 8698.9248, 8701.0176, 8704.443500000001, 8704.690999999999, 8705.521649999999, 8706.7554, 8708.2456, 8709.3443, 8710.36825, 8711.8485, 8712.58565, 8718.5964, 8722.05475, 8722.762149999999, 8723.4733, 8724.13995, 8726.132549999998, 8730.2676, 8733.9196, 8736.2716, 8738.337050000002, 8745.1011, 8745.52885, 8749.27145, 8750.11235, 8752.134900000001, 8755.75125, 8761.251349999999, 8768.74115, 8769.898949999999, 8770.9733, 8772.1307, 8773.34015, 8774.47275, 8775.6286, 8776.64965, 8778.7306, 8784.3053, 8786.901699999999, 8790.0786, 8794.3016, 8794.695, 8796.070049999998, 8799.86995, 8804.7965, 8807.93715, 8808.27385, 8809.95135, 8812.487400000002, 8813.7886, 8815.3081, 8817.61735, 8819.4745, 8822.15085, 8823.94785, 8824.70955, 8825.907500000001, 8829.8069, 8831.598399999999, 8832.0983, 8832.59, 8834.3818, 8835.762499999999, 8836.848699999999, 8838.42085, 8848.2095, 8849.723899999999, 8852.52995, 8857.38395, 8860.8436, 8861.60655, 8862.3751, 8866.88685, 8868.98835, 8871.24315, 8873.0152, 8876.7615, 8880.650249999999, 8883.76275, 8886.87695, 8888.4888, 8890.26225, 8892.3034, 8894.151249999999, 8894.9334, 8896.18105, 8897.3845, 8899.221300000001, 8902.12765, 8917.0405, 8917.76195, 8918.0483, 8919.001199999999, 8920.89955, 8923.54245, 8925.20605, 8929.2251, 8942.791000000001, 8946.27475, 8948.5162, 8950.54415, 8951.780149999999, 8956.511750000001, 8960.6775, 8965.6577, 8978.02575, 8979.81265, 8983.24775, 8995.8641, 8996.10845, 8997.786950000002, 8999.822, 9000.3558, 9001.6515, 9003.6724, 9004.8452, 9008.266650000001, 9012.8004, 9018.6968, 9021.6097, 9024.6128, 9025.4848, 9026.503, 9027.4416, 9029.49435, 9031.174599999998, 9031.522249999998, 9032.193449999999, 9032.99215, 9033.35775, 9034.303649999998, 9037.616750000001, 9038.7228, 9039.41865, 9040.51625, 9046.297149999999, 9050.0737, 9052.961500000001, 9056.87065, 9059.371299999999, 9060.8576, 9068.4691, 9076.68885, 9082.36585, 9089.3343, 9089.6764, 9091.9406, 9102.8194, 9103.3832, 9114.97975, 9116.48505, 9117.2372, 9117.98185, 9118.68435, 9119.4656, 9120.444449999999, 9123.91885, 9131.89545, 9138.087, 9140.3816, 9141.6121, 9146.59135, 9153.12945, 9156.213650000002, 9157.4559, 9158.9635, 9159.43325, 9160.590100000001, 9162.49525, 9164.0597, 9168.705300000001, 9170.0235, 9170.6687, 9172.52505, 9176.2301, 9180.83985, 9184.1852, 9189.177049999998, 9193.67975, 9194.4545, 9195.5908, 9196.3763, 9198.984, 9206.5834, 9212.694950000001, 9216.369050000001, 9218.0465, 9219.4815, 9231.5136, 9233.2221, 9235.360850000001, 9239.140899999999, 9241.2889, 9245.36065, 9247.8351, 9248.712650000001, 9249.33675, 9249.583, 9251.1717, 9253.92105, 9258.29795, 9258.557550000001, 9258.909200000002, 9259.77595, 9260.943299999999, 9263.176800000001, 9266.9391, 9269.604899999998, 9272.7543, 9275.1713, 9279.19075, 9281.03415, 9288.58625, 9289.52795, 9291.38305, 9293.92525, 9296.0864, 9298.4188, 9300.3964, 9303.39595, 9309.72635, 9310.2422, 9311.240999999998, 9312.0397, 9313.54275, 9323.9512, 9326.2898, 9328.178, 9330.096599999999, 9334.28545, 9336.322949999998, 9341.8136, 9344.1095, 9344.14255, 9345.2472, 9346.735949999998, 9354.919249999999, 9358.109, 9363.01995, 9366.58665, 9367.31395, 9374.04505, 9382.19915, 9388.29185, 9388.5133, 9397.7008, 9401.3528, 9405.53225, 9408.62885, 9408.996149999999, 9409.8621, 9416.1044, 9420.892249999999, 9426.9427, 9429.310850000002, 9429.91085, 9431.6322, 9433.13445, 9441.3675, 9446.1947, 9447.7193, 9450.146499999999, 9451.994449999998, 9453.63435, 9454.64545, 9458.08605, 9459.84685, 9461.6032, 9466.5998, 9467.4643, 9469.3356, 9473.4394, 9480.768349999998, 9484.21875, 9485.14095, 9490.0331, 9507.9394, 9511.91265, 9513.6731, 9523.08315, 9524.2585, 9527.89505, 9530.45435, 9530.5807, 9543.1573, 9543.615150000001, 9543.746299999999, 9544.50295, 9547.6022, 9549.74945, 9552.2004, 9554.08595, 9556.527, 9557.8841, 9564.8826, 9571.865600000001, 9577.37495, 9578.8452, 9586.25795, 9590.30585, 9594.4797, 9595.46285, 9598.44895, 9600.479200000002, 9612.53225, 9615.5758, 9616.90435, 9619.5572, 9625.45535, 9625.903549999999, 9626.914950000002, 9628.9009, 9631.473600000001, 9638.21095, 9641.34565, 9644.0887, 9645.45655, 9652.64195, 9654.06395, 9655.335299999999, 9656.85385, 9657.6332, 9659.655149999999, 9663.95565, 9667.1484, 9669.71105, 9674.39525, 9684.72665, 9688.3634, 9691.015500000001, 9693.701200000001, 9696.5116, 9699.4718, 9701.56915, 9705.799200000001, 9710.7661, 9712.23775, 9723.8084, 9724.73975, 9725.18895, 9726.1599, 9726.432850000001, 9727.90085, 9729.5137, 9729.8674, 9731.6679, 9733.76425, 9736.2108, 9745.773700000002, 9752.167300000001, 9754.08065, 9755.69315, 9756.527900000001, 9757.854350000001, 9758.6993, 9759.79355, 9761.7049, 9766.4442, 9768.561000000002, 9771.191350000001, 9773.255099999998, 9774.5075, 9775.65525, 9776.283449999999, 9777.1786, 9778.398700000002, 9780.014299999999, 9781.06755, 9781.4236, 9783.9931, 9786.316200000001, 9789.10735, 9794.9119, 9795.50735, 9796.84405, 9798.7835, 9809.9919, 9810.68835, 9811.0042, 9812.9434, 9817.03105, 9819.65215, 9821.8751, 9823.4973, 9825.26065, 9827.356899999999, 9829.49815, 9830.7731, 9831.868699999999, 9833.053199999998, 9835.8226, 9852.55355, 9857.53585, 9860.032200000001, 9863.2424, 9866.146, 9867.88145, 9869.3652, 9873.92455, 9878.2035, 9881.6533, 9882.33395, 9884.377700000001, 9887.213749999999, 9888.538349999999, 9890.84545, 9893.2506, 9899.18, 9907.864249999999, 9915.58735, 9918.158350000002, 9919.90205, 9921.0119, 9922.304, 9924.319950000001, 9924.4565, 9924.6549, 9927.808649999999, 9930.2563, 9933.00155, 9934.32995, 9936.4839, 9938.7171, 9940.0537, 9943.29905, 9946.56655, 9946.811549999999, 9948.02275, 9949.23385, 9953.488949999999, 9955.009450000001, 9957.252700000001, 9959.8138, 9962.543099999999, 9965.1122, 9966.6892, 9967.0269, 9967.30615, 9967.694650000001, 9972.071800000002, 9972.579099999999, 9973.26485, 9975.05025, 9977.1535, 9978.8322, 9980.2215, 9982.213049999998, 9983.6089, 9984.5754, 9986.983400000001, 9988.82895, 9989.590100000001, 9990.945800000001, 9992.8656, 9995.38955, 9997.8912, 10000.140449999999, 10000.8493, 10006.718799999999, 10009.73755, 10011.8285, 10012.3431, 10014.04525, 10020.64235, 10021.598450000001, 10022.753799999999, 10025.1909, 10027.116399999999, 10034.2776, 10037.26285, 10039.650249999999, 10040.3356, 10041.013299999999, 10042.2736, 10044.781, 10045.514350000001, 10045.8256, 10046.42095, 10050.42225, 10055.81105, 10058.42095, 10059.71475, 10060.0654, 10061.03155, 10063.5565, 10066.174500000001, 10068.13495, 10071.37845, 10076.43065, 10082.1944, 10084.9778, 10089.66075, 10091.8619, 10098.16705, 10100.63135, 10101.3433, 10102.836800000001, 10104.961800000001, 10105.98855, 10110.563549999999, 10112.3252, 10114.196, 10114.69945, 10115.0047, 10117.47145, 10123.3422, 10123.858750000001, 10127.4496, 10137.52625, 10145.7908, 10147.2101, 10148.37515, 10149.8786, 10152.01205, 10153.685849999998, 10157.1722, 10158.1228, 10159.049899999998, 10159.53595, 10159.94055, 10160.8655, 10162.83075, 10164.214049999999, 10169.32865, 10171.2203, 10176.4695, 10179.29215, 10183.156350000001, 10192.3788, 10197.42975, 10199.2949, 10200.34195, 10205.43515, 10208.26495, 10213.02215, 10217.37485, 10218.426200000002, 10219.692200000001, 10220.6859, 10224.842250000002, 10230.657650000001, 10234.0918, 10240.48385, 10244.0667, 10245.61535, 10248.45945, 10249.74875, 10253.751349999999, 10254.70865, 10256.57405, 10258.2503, 10260.035900000003, 10260.296150000002, 10263.50035, 10264.58755, 10265.49625, 10265.836500000001, 10268.20165, 10274.447900000001, 10276.142950000001, 10278.2013, 10282.625950000001, 10286.698, 10289.2011, 10294.98365, 10297.332900000001, 10306.6315, 10308.197900000001, 10312.37355, 10315.215100000001, 10317.64675, 10325.7337, 10327.276549999999, 10345.1506, 10347.284, 10348.43465, 10349.123, 10350.25605, 10351.45475, 10352.4936, 10357.849450000002, 10361.99515, 10363.172900000001, 10377.73095, 10379.62065, 10380.51855, 10382.7949, 10385.8357, 10388.337300000001, 10391.50885, 10393.49195, 10395.067899999998, 10408.77805, 10416.413700000001, 10422.981650000002, 10425.47895, 10427.57255, 10428.50745, 10430.6975, 10435.8264, 10445.105800000001, 10451.42275, 10452.204249999999, 10453.44025, 10454.819499999998, 10455.58615, 10457.16775, 10459.93695, 10461.58505, 10464.10065, 10467.84305, 10470.9254, 10471.1517, 10472.28445, 10474.855200000002, 10476.5267, 10476.755000000001, 10482.3061, 10485.383549999999, 10486.32485, 10488.057649999999, 10489.180349999999, 10489.88865, 10490.56485, 10500.609100000001, 10501.74295, 10502.603050000002, 10503.3887, 10503.99365, 10515.882099999999, 10522.4623, 10532.961749999999, 10534.3958, 10536.419600000001, 10538.46075, 10539.2845, 10542.437, 10545.5128, 10546.3726, 10547.2182, 10548.8986, 10551.1571, 10552.134549999999, 10555.28555, 10557.090199999999, 10560.93415, 10565.5249, 10574.4322, 10576.29105, 10576.9246, 10579.513050000001, 10581.583750000002, 10583.005799999999, 10593.66085, 10595.140800000001, 10599.295699999999, 10599.6325, 10599.95605, 10602.33465, 10607.11415, 10610.399099999999, 10615.861799999999, 10620.862400000002, 10626.66645, 10630.1789, 10643.8038, 10647.8699, 10653.0439, 10655.40815, 10656.4371, 10657.49825, 10657.8126, 10661.72765, 10662.22545, 10664.86405, 10669.46265, 10674.33925, 10677.64675, 10679.8084, 10682.36435, 10688.251400000001, 10690.9803, 10694.1218, 10699.027900000001, 10701.207849999999, 10708.573349999999, 10712.212599999999, 10715.49265, 10718.13505, 10720.2988, 10721.6538, 10727.627550000001, 10731.981749999999, 10733.78515, 10739.43755, 10740.99565, 10742.961, 10744.471450000001, 10745.6065, 10748.98905, 10753.40395, 10756.4729, 10760.2865, 10762.5295, 10764.99225, 10769.3171, 10776.75575, 10777.60715, 10778.4683, 10779.31755, 10782.7467, 10787.2395, 10791.907, 10796.715100000001, 10801.7853, 10805.91225, 10813.72065, 10817.47365, 10825.86345, 10838.5405, 10841.995050000001, 10850.44995, 10852.58195, 10857.548999999999, 10860.36695, 10861.311999999998, 10861.76725, 10862.489000000001, 10877.47675, 10884.600849999999, 10888.5186, 10889.13855, 10897.5225, 10899.5079, 10908.7425, 10914.6754, 10924.7091, 10929.239999999998, 10930.8018, 10935.2241, 10936.0072, 10937.99485, 10939.82165, 10941.11985, 10942.50215, 10943.201799999999, 10947.22535, 10951.194800000001, 10952.020700000001, 10954.9794, 10957.71195, 10960.982750000001, 10973.11815, 10974.16775, 10977.5245, 10981.82605, 11003.9778, 11005.945, 11009.647649999999, 11012.97805, 11016.116699999999, 11018.29275, 11023.920549999999, 11026.24405, 11026.33525, 11029.3367, 11034.930349999999, 11038.61405, 11043.921600000001, 11048.503250000002, 11049.1824, 11050.1823, 11050.9345, 11051.4571, 11059.7325, 11063.1471, 11065.8475, 11067.8487, 11068.043249999999, 11068.7324, 11070.1551, 11091.81135, 11111.158599999999, 11116.15215, 11127.89595, 11135.7419, 11145.557200000001, 11149.86935, 11154.388750000002, 11156.425150000001, 11159.435300000001, 11160.80025, 11163.7532, 11165.7384, 11172.26885, 11173.03125, 11173.7055, 11176.8688, 11178.860700000001, 11180.8086, 11181.42315, 11195.056550000001, 11201.9703, 11212.3635, 11215.89625, 11221.102149999999, 11225.265500000001, 11230.30575, 11234.717550000001, 11235.5956, 11238.35375, 11243.016950000001, 11246.298450000002, 11252.8225, 11254.907299999999, 11256.335149999999, 11259.165950000002, 11262.068050000002, 11262.9103, 11263.516200000002, 11263.9935, 11265.48675, 11270.7019, 11273.3901, 11276.69955, 11286.0232, 11292.25265, 11298.4796, 11299.3964, 11300.65925, 11302.25815, 11305.19405, 11308.06425, 11309.8886, 11312.78655, 11314.86265, 11319.316050000001, 11324.990600000001, 11334.31465, 11340.5415, 11345.18895, 11350.53715, 11351.759900000001, 11360.404449999998, 11370.20725, 11373.7647, 11374.59305, 11376.63325, 11378.38595, 11380.993499999999, 11387.55585, 11391.84895, 11394.09665, 11396.178199999998, 11398.19325, 11398.8122, 11400.2438, 11403.013050000001, 11406.0306, 11407.844099999998, 11408.423299999999, 11410.714650000002, 11418.616549999999, 11422.940999999999, 11431.399550000002, 11439.4911, 11442.0621, 11443.785100000001, 11447.136, 11451.138050000001, 11454.25215, 11456.16835, 11458.1297, 11460.8625, 11463.3364, 11464.20665, 11485.562300000001, 11487.236550000001, 11487.76045, 11488.4268, 11489.876400000001, 11492.74595, 11494.685000000001, 11495.4852, 11495.94285, 11498.697100000001, 11501.9314, 11509.18915, 11510.318, 11511.828, 11515.61715, 11515.711500000001, 11516.413550000001, 11518.6885, 11519.0454, 11520.96535, 11524.89935, 11527.5298, 11530.163100000002, 11533.6556, 11536.732, 11538.5805, 11540.01655, 11540.7985, 11541.7383, 11543.68545, 11547.296600000001, 11555.6423, 11557.626, 11561.8394, 11569.9107, 11570.1862, 11580.889149999999, 11583.81055, 11587.239699999998, 11588.3553, 11591.934949999999, 11595.283899999999, 11598.483349999999, 11601.73765, 11608.8538, 11610.1087, 11617.1109, 11618.745449999999, 11622.88495, 11626.537649999998, 11627.9221, 11634.277399999999, 11637.13435, 11641.68895, 11647.590799999998, 11650.556799999998, 11651.19545, 11666.87145, 11668.4369, 11670.1011, 11671.8093, 11673.23755, 11676.192900000002, 11678.3072, 11682.861949999999, 11688.0941, 11690.163349999999, 11690.575099999998, 11691.71645, 11696.9267, 11714.505, 11716.2938, 11717.76535, 11720.15175, 11724.27535, 11728.20275, 11729.39715, 11731.06565, 11733.21185, 11739.1003, 11747.15915, 11751.4283, 11758.18755, 11759.59145, 11761.6171, 11766.1374, 11769.9562, 11775.1759, 11776.400099999999, 11777.6201, 11786.780449999998, 11787.8458, 11788.94055, 11790.63475, 11792.409899999999, 11798.4158, 11804.462500000001, 11808.016499999998, 11810.161, 11813.3475, 11814.645250000001, 11814.87705, 11815.9303, 11819.73525, 11827.75085, 11832.041099999999, 11832.61985, 11832.954600000001, 11836.336650000001, 11838.24295, 11838.590800000002, 11838.97625, 11841.315299999998, 11844.3768, 11846.849750000001, 11848.87435, 11851.113000000001, 11854.341, 11856.676300000001, 11859.212650000001, 11868.7206, 11876.30695, 11879.80085, 11883.10455, 11889.54075, 11896.442350000001, 11898.96895, 11913.940750000002, 11916.887, 11919.4233, 11923.697, 11925.980500000001, 11929.047450000002, 11930.801800000001, 11931.434, 11931.9209, 11932.644949999998, 11933.345449999999, 11935.0314, 11936.160899999999, 11936.833700000001, 11944.023949999999, 11947.128649999999, 11950.001, 11959.1359, 11962.71595, 11965.6947, 11968.225450000002, 11972.21545, 11975.6463, 11980.055199999999, 11982.0839, 11994.88945, 11998.2071, 11999.7219, 12002.097399999999, 12002.94985, 12004.916549999998, 12005.5788, 12008.775950000001, 12012.325250000002, 12014.55575, 12018.04465, 12019.791150000001, 12020.248899999999, 12020.9023, 12021.811849999998, 12031.277549999999, 12031.3352, 12031.491999999998, 12038.71205, 12039.822199999999, 12041.857399999999, 12043.73445, 12047.1969, 12053.838749999999, 12055.23885, 12055.92885, 12064.68975, 12068.195, 12077.2916, 12078.734199999999, 12092.736649999999, 12096.1081, 12098.943449999999, 12102.6611, 12107.25905, 12108.683100000002, 12110.093550000001, 12115.17645, 12118.1061, 12119.34735, 12120.7781, 12122.85755, 12126.2078, 12128.613000000001, 12132.120499999999, 12134.06175, 12134.730150000001, 12136.1725, 12137.987949999999, 12140.04405, 12143.8352, 12146.6124, 12147.52115, 12151.31535, 12154.60705, 12167.9284, 12175.60525, 12177.623599999999, 12182.7099, 12183.482250000001, 12185.375799999998, 12187.608549999999, 12193.15415, 12197.65535, 12202.5958, 12212.10485, 12214.113949999999, 12216.8214, 12220.592550000001, 12224.62095, 12231.3945, 12235.76125, 12236.507700000002, 12237.260850000002, 12237.88535, 12239.585350000001, 12242.40685, 12244.06, 12246.313600000001, 12249.21155, 12256.611, 12268.67715, 12270.260699999999, 12271.4647, 12273.1387, 12274.18865, 12277.501, 12281.415949999999, 12283.779449999998, 12285.7458, 12286.568749999999, 12288.17245, 12289.72135, 12289.93635, 12290.2369, 12290.6034, 12292.0883, 12304.8039, 12306.62765, 12309.544300000001, 12310.60285, 12316.314749999998, 12320.272949999999, 12323.538499999999, 12326.965, 12329.367699999999, 12335.4438, 12339.7515, 12341.48725, 12345.80075, 12350.8472, 12369.5475, 12376.49555, 12377.5381, 12378.68375, 12382.8629, 12386.78945, 12397.193800000001, 12397.461299999999, 12398.170300000002, 12401.4542, 12404.74595, 12409.08485, 12420.875250000001, 12422.12895, 12429.9248, 12432.03195, 12433.62555, 12438.45395, 12440.07865, 12443.670000000002, 12448.24825, 12448.500250000001, 12450.148700000002, 12452.7757, 12458.98385, 12460.906200000001, 12462.5254, 12464.9496, 12466.3069, 12467.85795, 12476.46365, 12479.203150000001, 12481.4107, 12483.48245, 12490.3889, 12495.80015, 12496.811849999998, 12502.2134, 12503.65245, 12507.045450000001, 12512.6381, 12516.87375, 12525.1129, 12527.593499999999, 12531.8769, 12536.084149999999, 12541.1797, 12542.510149999998, 12552.270700000001, 12553.991999999998, 12555.192949999999, 12555.44775, 12556.922900000001, 12559.039850000001, 12561.6817, 12563.90435, 12568.194049999998, 12572.40425, 12574.5281, 12576.2719, 12577.248749999999, 12577.8744, 12581.84245, 12586.19485, 12596.2202, 12603.89005, 12605.3417, 12607.92625, 12609.54865, 12609.6757, 12610.3122, 12616.71045, 12625.9169, 12626.9872, 12627.82515, 12628.1034, 12630.6302, 12638.94045, 12650.42145, 12650.6672, 12657.375049999999, 12660.56835, 12664.34945, 12668.1486, 12670.984050000001, 12672.057499999999, 12672.8642, 12673.810549999998, 12674.53085, 12676.55555, 12678.81245, 12686.822, 12690.3575, 12693.771, 12696.358699999999, 12698.091699999999, 12706.429750000001, 12706.975600000002, 12708.16335, 12709.3893, 12709.9226, 12714.798200000001, 12717.86855, 12719.72715, 12721.4849, 12722.727200000001, 12724.554100000001, 12727.0572, 12740.163349999999, 12740.66475, 12742.9635, 12744.347249999999, 12748.9561, 12749.96295, 12751.5191, 12754.89415, 12757.10385, 12768.9719, 12771.70535, 12787.16295, 12790.348549999999, 12798.9588, 12812.471150000001, 12837.14015, 12842.05025, 12844.011849999999, 12846.5982, 12850.015449999999, 12852.8269, 12853.53385, 12853.947499999998, 12858.2037, 12861.26325, 12863.02065, 12864.857250000001, 12866.203850000002, 12867.47455, 12869.9251, 12873.62325, 12876.057999999999, 12877.0381, 12880.68135, 12881.70975, 12885.51745, 12890.36185, 12891.483099999998, 12891.895649999999, 12893.0168, 12894.444599999999, 12897.2647, 12899.818899999998, 12902.33555, 12903.54885, 12909.92625, 12912.213499999998, 12914.791, 12917.67475, 12926.21255, 12929.701949999999, 12932.3742, 12936.01095, 12937.82015, 12942.1623, 12944.2685, 12949.73885, 12950.6448, 12958.22235, 12961.22125, 12981.454399999999, 12981.902849999999, 12984.033950000001, 12993.64585, 13001.2811, 13007.7348, 13016.05835, 13023.15175, 13025.13375, 13029.42785, 13036.12725, 13040.063149999998, 13042.44365, 13047.3534, 13048.4476, 13053.466649999998, 13060.19615, 13066.096099999999, 13067.520400000001, 13067.85985, 13068.3865, 13068.607800000002, 13071.118300000002, 13075.20705, 13078.734100000001, 13081.06085, 13087.22395, 13093.5654, 13096.82995, 13099.6188, 13100.19965, 13101.8158, 13105.378400000001, 13107.21115, 13109.254099999998, 13126.120350000001, 13128.5816, 13131.45475, 13133.314849999999, 13134.8207, 13136.1755, 13139.66015, 13142.8619, 13145.0821, 13147.74495, 13150.49715, 13160.1548, 13162.99135, 13165.683949999999, 13173.358199999999, 13179.56575, 13180.6144, 13181.277900000001, 13183.1024, 13187.663499999999, 13196.4295, 13227.4147, 13230.46145, 13233.3634, 13236.2026, 13243.2577, 13250.797199999999, 13253.3112, 13254.50375, 13261.739099999999, 13268.128349999999, 13268.4579, 13272.9583, 13283.4931, 13290.73465, 13292.7147, 13299.6186, 13303.75605, 13319.50895, 13326.65845, 13333.25315, 13342.456699999999, 13351.87485, 13356.75565, 13363.70205, 13370.45595, 13374.51715, 13389.832600000002, 13392.80375, 13395.4988, 13403.31175, 13404.782449999999, 13409.0828, 13414.21915, 13428.06535, 13439.32995, 13446.093949999999, 13449.08885, 13452.847450000001, 13454.2672, 13458.4159, 13461.0383, 13470.053199999998, 13477.510900000001, 13505.032299999999, 13532.06755, 13533.86675, 13536.376049999999, 13538.5245, 13540.0642, 13542.44615, 13545.2806, 13549.46775, 13568.0216, 13584.08495, 13593.2105, 13598.5933, 13601.47635, 13616.953449999999, 13625.6152, 13635.00965, 13643.45855, 13647.4142, 13657.99785, 13667.7294, 13671.53915, 13677.7612, 13685.53025, 13689.677, 13690.649150000001, 13691.7265, 13695.74125, 13719.28615, 13721.69835, 13723.3956, 13725.91285, 13728.330699999999, 13765.978350000001, 13777.083200000001, 13780.9512, 13788.00575, 13797.717400000001, 13814.719700000001, 13816.561700000002, 13847.293699999998, 13859.9008, 13874.27345, 13895.9781, 13903.786950000002, 13914.4972, 13924.3312, 13935.36975, 13955.987850000001, 13978.46435, 13986.45915, 13989.7937, 13995.6312, 14005.553899999999, 14026.662550000001, 14054.4308, 14068.484, 14070.1423, 14074.47265, 14079.57115, 14083.06475, 14085.930199999999, 14088.44545, 14105.832600000002, 14107.19915, 14111.48215, 14114.999749999999, 14151.8048, 14173.03185, 14186.85395, 14193.986649999999, 14202.7664, 14236.364099999999, 14254.32135, 14271.76685, 14291.36535, 14308.352350000001, 14320.0292, 14322.16705, 14339.4922, 14354.43995, 14373.68245, 14378.406149999999, 14384.674350000001, 14424.75215, 14462.41875, 14490.328300000001, 14539.569950000001, 14581.40795, 14584.4777, 14616.523, 14635.341199999999, 14652.02635, 14684.38025, 14700.8273, 14719.2805, 14734.0631, 14761.586, 14771.330750000001, 14784.3567, 14794.3648, 14798.32405, 14801.80905, 14834.1624, 14872.180049999999, 14882.340200000002, 14887.34865, 14888.48025, 14896.99715, 14910.2461, 14915.627400000001, 14922.8973, 14963.68215, 15009.06565, 15036.70505, 15054.257249999999, 15063.10775, 15071.81425, 15132.64715, 15134.19985, 15163.429100000001, 15191.950649999999, 15226.3442, 15237.4862, 15241.24585, 15250.18865, 15264.633150000001, 15274.054349999999, 15303.412400000001, 15321.4672, 15332.405999999999, 15337.18445, 15342.057250000002, 15352.46955, 15370.502649999999, 15440.926650000001, 15445.99715, 15461.024549999998, 15487.1196, 15516.004250000002, 15592.490300000001, 15608.106350000002, 15720.65845, 15794.68085, 15844.89545, 15859.568399999998, 15899.9041, 15933.770550000001, 16031.405349999999, 16072.729049999998, 16106.83095, 16118.8058, 16153.1119, 16203.51675, 16248.96345, 16289.222249999999, 16393.16895, 16468.7081, 16660.321949999998, 16812.95325, 16845.0241, 16893.768149999996, 16943.3773, 16967.17205, 16999.257149999998, 17031.48445, 17245.79685, 17321.689899999998, 17413.66175, 17617.978450000002, 17648.33435, 17663.8652, 17719.8799, 17806.8681, 17874.627399999998, 17972.4441, 18021.98805, 18058.99445, 18314.240749999997, 18407.97255, 18456.957499999997, 18469.3393, 18505.64995, 18596.631, 18726.1286, 18804.803549999997, 18988.7395, 19184.56805, 19395.567600000002, 19610.690949999997, 19995.2292, 20892.007149999998, 21012.725899999998, 21386.639600000002, 21429.598599999998, 21534.702699999998, 22225.223550000002, 22451.3396, 22662.5725, 23000.6352, 23224.16035, 23688.5856, 23739.992100000003, 23761.761599999998, 24123.36965, 24517.6261, 25431.466699999997, 26130.9968, 27577.400999999998, 27989.1392, 28529.03325, 28784.80055, 28877.566699999996, 29029.761049999997, 29158.5565, 29954.6427, 37417.3663])
labels = array([0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0])
def eqenergy(rows):
    return np.sum(rows, axis=1)
def classify(rows):
    energys = eqenergy(rows)

    def thresh_search(input_energys):
        numers = np.searchsorted(energy_thresholds, input_energys, side='left')-1
        indys = np.argwhere(np.logical_and(numers<len(energy_thresholds), numers>=0)).reshape(-1)
        defaultindys = np.argwhere(np.logical_not(np.logical_and(numers<len(energy_thresholds), numers>=0))).reshape(-1)
        outputs = np.zeros(input_energys.shape[0])
        outputs[indys] = labels[numers[indys]]
        outputs[defaultindys] = 1.0
        return outputs
    return thresh_search(energys)

numthresholds = 3509



# Main method
model_cap = numthresholds


def Validate(file):
    cleanarr = np.loadtxt(file, delimiter=',', dtype='float64')


    if n_classes == 2:
        #note that classification is a single line of code
        outputs = classify(cleanarr[:, :-1])


        #metrics
        count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0 = 0, 0, 0, 0, 0, 0, 0, 0
        correct_count = int(np.sum(outputs.reshape(-1) == cleanarr[:, -1].reshape(-1)))
        count = outputs.shape[0]
        num_TP = int(np.sum(np.logical_and(outputs.reshape(-1) == 1, cleanarr[:, -1].reshape(-1) == 1)))
        num_TN = int(np.sum(np.logical_and(outputs.reshape(-1) == 0, cleanarr[:, -1].reshape(-1) == 0)))
        num_FN = int(np.sum(np.logical_and(outputs.reshape(-1) == 0, cleanarr[:, -1].reshape(-1) == 1)))
        num_FP = int(np.sum(np.logical_and(outputs.reshape(-1) == 1, cleanarr[:, -1].reshape(-1) == 0)))
        num_class_0 = int(np.sum(cleanarr[:, -1].reshape(-1) == 0))
        num_class_1 = int(np.sum(cleanarr[:, -1].reshape(-1) == 1))
        return count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0


    else:
        #validation
        outputs = classify(cleanarr[:, :-1])


        #metrics
        count, correct_count = 0, 0
        numeachclass = {}
        for k, o in enumerate(outputs):
            if int(o) == int(float(cleanarr[k, -1])):
                correct_count += 1
            if int(float(cleanarr[k, -1])) in numeachclass.keys():
                numeachclass[int(float(cleanarr[k, -1]))] += 1
            else:
                numeachclass[int(float(cleanarr[k, -1]))] = 0
            count += 1
        return count, correct_count, numeachclass, outputs, cleanarr[:, -1]


#Predict on unlabeled data
def Predict(file, get_key, headerless, preprocessedfile, classmapping):
    cleanarr = np.loadtxt(file, delimiter=',', dtype='float64')
    with open(preprocessedfile, 'r') as csvinput:
        dirtyreader = csv.reader(csvinput)

        #print original header
        if (not headerless):
            print(','.join(next(dirtyreader, None) + ["Prediction"]))

        outputs = classify(cleanarr)

        for k, row in enumerate(dirtyreader):
            print(str(','.join(str(j) for j in ([i for i in row]))) + ',' + str(get_key(int(outputs[k]), classmapping)))



#Main
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Predictor trained on '+TRAINFILE)
    parser.add_argument('csvfile', type=str, help='CSV file containing test set (unlabeled).')
    parser.add_argument('-validate', action='store_true', help='Validation mode. csvfile must be labeled. Output is classification statistics rather than predictions.')
    parser.add_argument('-cleanfile', action='store_true', help='Use this flag to save prediction time if the csvfile you are passing has already been preprocessed. Implies headerless.')
    parser.add_argument('-headerless', help='Do not treat the first line of csvfile as a header.', action='store_true')
    args = parser.parse_args()
    faulthandler.enable()

    #clean if not already clean
    if not args.cleanfile:
        cleanfile = tempfile.NamedTemporaryFile().name
        preprocessedfile = tempfile.NamedTemporaryFile().name
        preprocess(args.csvfile,preprocessedfile,args.headerless,(not args.validate))
        get_key, classmapping = clean(preprocessedfile, cleanfile, -1, args.headerless, (not args.validate))
    else:
        cleanfile=args.csvfile
        preprocessedfile=args.csvfile
        get_key = lambda x, y: x
        classmapping = {}

    #Predict or Validate?
    if not args.validate:
        Predict(cleanfile, get_key, args.headerless, preprocessedfile, classmapping)


    else:
        print("Classifier Type: Quick Clustering")
        if n_classes == 2:
            count, correct_count, num_TP, num_TN, num_FP, num_FN, num_class_1, num_class_0 = Validate(cleanfile)
        else:
            count, correct_count, numeachclass, preds, true_labels = Validate(cleanfile)


        #validation report
        if n_classes == 2:
            #Base metrics
            FN = float(num_FN) * 100.0 / float(count)
            FP = float(num_FP) * 100.0 / float(count)
            TN = float(num_TN) * 100.0 / float(count)
            TP = float(num_TP) * 100.0 / float(count)
            num_correct = correct_count

            #Calculated Metrics
            if int(num_TP + num_FN) != 0:
                TPR = num_TP / (num_TP + num_FN) # Sensitivity, Recall
            if int(num_TN + num_FP) != 0:
                TNR = num_TN / (num_TN + num_FP) # Specificity
            if int(num_TP + num_FP) != 0:
                PPV = num_TP / (num_TP + num_FP) # Recall
            if int(num_FN + num_TP) != 0:
                FNR = num_FN / (num_FN + num_TP) # Miss rate
            if int(2 * num_TP + num_FP + num_FN) != 0:
                FONE = 2 * num_TP / (2 * num_TP + num_FP + num_FN) # F1 Score
            if int(num_TP + num_FN + num_FP) != 0:
                TS = num_TP / (num_TP + num_FN + num_FP) # Critical Success Index
            #Best Guess Accuracy
            randguess = int(float(10000.0 * max(num_class_1, num_class_0)) / count) / 100.0
            #Model Accuracy
            modelacc = int(float(num_correct * 10000) / count) / 100.0
            #Report
            print("System Type:                        Binary classifier")
            print("Best-guess accuracy:                {:.2f}%".format(randguess))
            print("Model accuracy:                     {:.2f}%".format(modelacc) + " (" + str(int(num_correct)) + "/" + str(count) + " correct)")
            print("Improvement over best guess:        {:.2f}%".format(modelacc - randguess) + " (of possible " + str(round(100 - randguess, 2)) + "%)")
            print("Model capacity (MEC):               {:.0f} bits".format(model_cap))
            print("Generalization ratio:               {:.2f}".format(int(float(num_correct * 100) / model_cap) / 100.0) + " bits/bit")
            print("Model efficiency:                   {:.2f}%/parameter".format(int(100 * (modelacc - randguess) / model_cap) / 100.0))
            print("System behavior")
            print("True Negatives:                     {:.2f}%".format(TN) + " (" + str(int(num_TN)) + "/" + str(count) + ")")
            print("True Positives:                     {:.2f}%".format(TP) + " (" + str(int(num_TP)) + "/" + str(count) + ")")
            print("False Negatives:                    {:.2f}%".format(FN) + " (" + str(int(num_FN)) + "/" + str(count) + ")")
            print("False Positives:                    {:.2f}%".format(FP) + " (" + str(int(num_FP)) + "/" + str(count) + ")")
            if int(num_TP + num_FN) != 0:
                print("True Pos. Rate/Sensitivity/Recall:  {:.2f}".format(TPR))
            if int(num_TN + num_FP) != 0:
                print("True Neg. Rate/Specificity:         {:.2f}".format(TNR))
            if int(num_TP + num_FP) != 0:
                print("Precision:                          {:.2f}".format(PPV))
            if int(2 * num_TP + num_FP + num_FN) != 0:
                print("F-1 Measure:                        {:.2f}".format(FONE))
            if int(num_TP + num_FN) != 0:
                print("False Negative Rate/Miss Rate:      {:.2f}".format(FNR))
            if int(num_TP + num_FN + num_FP) != 0:
                print("Critical Success Index:             {:.2f}".format(TS))

        #Multiclass
        else:
            num_correct = correct_count
            modelacc = int(float(num_correct * 10000) / count) / 100.0
            randguess = round(max(numeachclass.values()) / sum(numeachclass.values()) * 100, 2)
            print("System Type:                        " + str(n_classes) + "-way classifier")
            print("Best-guess accuracy:                {:.2f}%".format(randguess))
            print("Model accuracy:                     {:.2f}%".format(modelacc) + " (" + str(int(num_correct)) + "/" + str(count) + " correct)")
            print("Improvement over best guess:        {:.2f}%".format(modelacc - randguess) + " (of possible " + str(round(100 - randguess, 2)) + "%)")
            print("Model capacity (MEC):               {:.0f} bits".format(model_cap))
            print("Generalization ratio:               {:.2f}".format(int(float(num_correct * 100) / model_cap) / 100.0) + " bits/bit")
            try:
                import numpy as np # For numpy see: http://numpy.org
                from numpy import array
            except:
                print("Note: If you install numpy (https://www.numpy.org) and scipy (https://www.scipy.org) this predictor generates a confusion matrix")

            def confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None):
                #check for numpy/scipy is imported
                try:
                    from scipy.sparse import coo_matrix #required for multiclass metrics
                except:
                    print("Note: If you install scipy (https://www.scipy.org) this predictor generates a confusion matrix")
                    sys.exit()
                # Compute confusion matrix to evaluate the accuracy of a classification.
                # By definition a confusion matrix :math:C is such that :math:C_{i, j}
                # is equal to the number of observations known to be in group :math:i and
                # predicted to be in group :math:j.
                # Thus in binary classification, the count of true negatives is
                # :math:C_{0,0}, false negatives is :math:C_{1,0}, true positives is
                # :math:C_{1,1} and false positives is :math:C_{0,1}.
                # Read more in the :ref:User Guide <confusion_matrix>.
                # Parameters
                # ----------
                # y_true : array-like of shape (n_samples,)
                # Ground truth (correct) target values.
                # y_pred : array-like of shape (n_samples,)
                # Estimated targets as returned by a classifier.
                # labels : array-like of shape (n_classes), default=None
                # List of labels to index the matrix. This may be used to reorder
                # or select a subset of labels.
                # If None is given, those that appear at least once
                # in y_true or y_pred are used in sorted order.
                # sample_weight : array-like of shape (n_samples,), default=None
                # Sample weights.
                # normalize : {'true', 'pred', 'all'}, default=None
                # Normalizes confusion matrix over the true (rows), predicted (columns)
                # conditions or all the population. If None, confusion matrix will not be
                # normalized.
                # Returns
                # -------
                # C : ndarray of shape (n_classes, n_classes)
                # Confusion matrix.
                # References
                # ----------
                if labels is None:
                    labels = np.array(list(set(list(y_true.astype('int')))))
                else:
                    labels = np.asarray(labels)
                    if np.all([l not in y_true for l in labels]):
                        raise ValueError("At least one label specified must be in y_true")


                if sample_weight is None:
                    sample_weight = np.ones(y_true.shape[0], dtype=np.int64)
                else:
                    sample_weight = np.asarray(sample_weight)
                if y_true.shape[0]!=y_pred.shape[0]:
                    raise ValueError("y_true and y_pred must be of the same length")

                if normalize not in ['true', 'pred', 'all', None]:
                    raise ValueError("normalize must be one of {'true', 'pred', 'all', None}")


                n_labels = labels.size
                label_to_ind = {y: x for x, y in enumerate(labels)}
                # convert yt, yp into index
                y_pred = np.array([label_to_ind.get(x, n_labels + 1) for x in y_pred])
                y_true = np.array([label_to_ind.get(x, n_labels + 1) for x in y_true])
                # intersect y_pred, y_true with labels, eliminate items not in labels
                ind = np.logical_and(y_pred < n_labels, y_true < n_labels)
                y_pred = y_pred[ind]
                y_true = y_true[ind]
                # also eliminate weights of eliminated items
                sample_weight = sample_weight[ind]
                # Choose the accumulator dtype to always have high precision
                if sample_weight.dtype.kind in {'i', 'u', 'b'}:
                    dtype = np.int64
                else:
                    dtype = np.float64
                cm = coo_matrix((sample_weight, (y_true, y_pred)), shape=(n_labels, n_labels), dtype=dtype,).toarray()


                with np.errstate(all='ignore'):
                    if normalize == 'true':
                        cm = cm / cm.sum(axis=1, keepdims=True)
                    elif normalize == 'pred':
                        cm = cm / cm.sum(axis=0, keepdims=True)
                    elif normalize == 'all':
                        cm = cm / cm.sum()
                    cm = np.nan_to_num(cm)
                return cm


            print("Confusion Matrix:")
            mtrx = confusion_matrix(np.array(true_labels).reshape(-1), np.array(preds).reshape(-1))
            mtrx = mtrx / np.sum(mtrx) * 100.0
            print(' ' + np.array2string(mtrx, formatter={'float': (lambda x: '{:.2f}%'.format(round(float(x), 2)))})[1:-1])



    #remove tempfile if created
    if not args.cleanfile: 
        os.remove(cleanfile)
        os.remove(preprocessedfile)


